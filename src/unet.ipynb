{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline # This allows the matplotlib plots to be displayed inline in a Jupyter Notebook.\n",
    "\n",
    "%load_ext tensorboard # This loads the TensorBoard extension for Jupyter Notebook, allowing you to visualize training metrics.\n",
    "\n",
    "# Importing the necessary modules\n",
    "import os                   # Operating System functions (read/write files, create directories etc.)\n",
    "from pathlib import Path    # Object-oriented filesystem paths\n",
    "import imageio              # Reading/Writing a wide range of image data\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import numpy as np          # Numerical computations library\n",
    "from PIL import Image       # Python Imaging Library\n",
    "import torch                # PyTorch machine learning library\n",
    "from torch.utils.data import Dataset, DataLoader  # Dataset and DataLoader classes for custom data loading\n",
    "from torch.utils.tensorboard import SummaryWriter  # For logging to TensorBoard\n",
    "import torch.nn as nn           # Neural Networks module in PyTorch\n",
    "from torchvision import transforms  # Transformations for image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-net model from exercise 5\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net implementation\n",
    "    Arguments:\n",
    "      in_channels: number of input channels\n",
    "      out_channels: number of output channels\n",
    "      final_activation: activation applied to the network output\n",
    "    \"\"\"\n",
    "\n",
    "    # _conv_block and _upsampler are just helper functions to\n",
    "    # construct the model.\n",
    "    # encapsulating them like so also makes it easy to re-use\n",
    "    # the model implementation with different architecture elements\n",
    "\n",
    "    # Convolutional block for single layer of the decoder / encoder\n",
    "    # we apply two 2d convolutions with relu activation\n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    # upsampling via transposed 2d convolutions\n",
    "    def _upsampler(self, in_channels, out_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, depth=4, final_activation=None):\n",
    "        super().__init__()\n",
    "\n",
    "        assert depth < 10, \"Max supported depth is 9\"\n",
    "\n",
    "        # the depth (= number of encoder / decoder levels) is\n",
    "        # hard-coded to 4\n",
    "        self.depth = depth\n",
    "\n",
    "        # the final activation must either be None or a Module\n",
    "        if final_activation is not None:\n",
    "            assert isinstance(\n",
    "                final_activation, nn.Module\n",
    "            ), \"Activation must be torch module\"\n",
    "\n",
    "        # all lists of conv layers (or other nn.Modules with parameters) must be wraped\n",
    "        # itnto a nn.ModuleList\n",
    "\n",
    "        # modules of the encoder path\n",
    "        self.encoder = nn.ModuleList(\n",
    "            [\n",
    "                self._conv_block(in_channels, 16),\n",
    "                self._conv_block(16, 32),\n",
    "                self._conv_block(32, 64),\n",
    "                self._conv_block(64, 128),\n",
    "                self._conv_block(128, 256),\n",
    "                self._conv_block(256, 512),\n",
    "                self._conv_block(512, 1024),\n",
    "                self._conv_block(1024, 2048),\n",
    "                self._conv_block(2048, 4096),\n",
    "            ][:depth]\n",
    "        )\n",
    "        # the base convolution block\n",
    "        if depth >= 1:\n",
    "            self.base = self._conv_block(2 ** (depth + 3), 2 ** (depth + 4))\n",
    "        else:\n",
    "            self.base = self._conv_block(1, 2 ** (depth + 4))\n",
    "        # modules of the decoder path\n",
    "        self.decoder = nn.ModuleList(\n",
    "            [\n",
    "                self._conv_block(8192, 4096),\n",
    "                self._conv_block(4096, 2048),\n",
    "                self._conv_block(2048, 1024),\n",
    "                self._conv_block(1024, 512),\n",
    "                self._conv_block(512, 256),\n",
    "                self._conv_block(256, 128),\n",
    "                self._conv_block(128, 64),\n",
    "                self._conv_block(64, 32),\n",
    "                self._conv_block(32, 16),\n",
    "            ][-depth:]\n",
    "        )\n",
    "\n",
    "        # the pooling layers; we use 2x2 MaxPooling\n",
    "        self.poolers = nn.ModuleList([nn.MaxPool2d(2) for _ in range(self.depth)])\n",
    "        # the upsampling layers\n",
    "        self.upsamplers = nn.ModuleList(\n",
    "            [\n",
    "                self._upsampler(8192, 4096),\n",
    "                self._upsampler(4096, 2048),\n",
    "                self._upsampler(2048, 1024),\n",
    "                self._upsampler(1024, 512),\n",
    "                self._upsampler(512, 256),\n",
    "                self._upsampler(256, 128),\n",
    "                self._upsampler(128, 64),\n",
    "                self._upsampler(64, 32),\n",
    "                self._upsampler(32, 16),\n",
    "            ][-depth:]\n",
    "        )\n",
    "        # output conv and activation\n",
    "        # the output conv is not followed by a non-linearity, because we apply\n",
    "        # activation afterwards\n",
    "        self.out_conv = nn.Conv2d(16, out_channels, 1)\n",
    "        self.activation = final_activation\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        # apply encoder path\n",
    "        encoder_out = []\n",
    "        for level in range(self.depth):\n",
    "            x = self.encoder[level](x)\n",
    "            encoder_out.append(x)\n",
    "            x = self.poolers[level](x)\n",
    "\n",
    "        # apply base\n",
    "        x = self.base(x)\n",
    "\n",
    "        # apply decoder path\n",
    "        encoder_out = encoder_out[::-1]\n",
    "        for level in range(self.depth):\n",
    "            x = self.upsamplers[level](x)\n",
    "            x = self.decoder[level](torch.cat((x, encoder_out[level]), dim=1))\n",
    "\n",
    "        # apply output conv and activation (if given)\n",
    "        x = self.out_conv(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage: create U-net object\n",
    "\n",
    "unetObjectA = UNet(\n",
    "    in_channels=1, out_channels=1, depth=4, final_activation=torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
